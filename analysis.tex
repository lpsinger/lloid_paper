\section{Implementation}

Our method involves an offline planning stage and an online, low latency filtering stage.

\subsection{Planning stage}

The planning stage proceeds as follows.  First, the templates are chosen by covering the space of mass parameters with a hexagonal grid \cite{PhysRevD.76.102004} in order to satisfy the minimum match criterion.  Next, the templates are subdivided into groups of neighbors called ``sub-banks'' that are appropriately sized so that each bank can be efficiently handled by a single machine.  (In this paper, we will only study a single sub-bank.)  Using our understanding of the time-frequency evolution of the templates, we choose time slice boundaries such that all of the templates within this sub-bank are sub-critically sampled at progressively lower sample rates.  Next, the templates within this sub-bank are realized as \textsc{fir} filter coefficients.  For each time slice, the templates are downsampled to the appropriate sample rate.  Finally, the \textsc{svd} is applied to each time slice in order to produce a set of orthogonal \textsc{fir} filters and a reconstruction matrix that maps them back to the original templates.  The downsampled orthogonal \textsc{fir} filter coefficients, the reconstruction matrix, and the time slice boundaries are all saved to disk.

\subsection{Filtering stage}

We have implemented a prototype of the low latency filtering stage using an open source signal processing environment called GStreamer \cite{gstreamer}.  GStreamer is a vital component of many Linux systems, providing media playback, authoring, and streaming on devices from cell phones to desktop computers to streaming media servers.  It turns out that it is also uniquely suited to gravitational wave data analysis.  In our application, GStreamer excels at queueing, synchronizing, adding, and bookkeeping many different signals at different sample rates.  It also provides some useful signal processing primitives such as decimators, \textsc{fir} filters, and interpolators.  Most importantly, it permits us to recruit all of the host system's \textsc{cpu}s without having to write complicated and error-prone multithreaded code.

\begin{figure}[htbp]
	\includegraphics{figures/lloid-diagram.pdf}
	\caption{Schematic of LLOID pipeline illustrating signal flow.  Circles with arrows represent upsampling \protect\includegraphics{figures/upsample-symbol.pdf} or downsampling \protect\includegraphics{figures/downsample-symbol.pdf}.  Circles with plus signs represent summing junctions \protect\includegraphics{figures/adder-symbol.pdf}.  Squares \protect\includegraphics{figures/fir-symbol.pdf} stand for FIR filters.  Sample rate decreases from the top of the diagram to the bottom.}
\end{figure}

The filter pipeline consists of six distinct stages.

\subsubsection{Decimation}

First, the sample rate of the whitened detector data is reduced to successively lower sample rates by decimation.  Decimation involves applying an antialiasing filter to the data, and then downsampling by deleting samples.  We use a 192-tap \textsc{fir} decimator provided by GStreamer.

\subsubsection{Time delays}

Each decimated detector data stream becomes the input for one time slice, but it must be appropriately delayed.

\subsubsection{Orthogonal \textsc{fir} filters

\subsubsection{Reconstruction}

\subsubsection{Interpolation}

\subsubsection{SNR accumulation}

%Our new method consists of six distinct stages:
%\begin{enumerate}
%\item\label{item:decimation} Decimation of the detector data to successively lower sample rates
%\item\label{item:delay} Delay lines to appropriately synchronize of all of the time slices
%\item\label{item:ortho} Application of orthogonal \textsc{fir} filters to the decimated detector data
%\item\label{item:reconstruct} Mixing of orthogonal filter output using reconstruction matrices
%\item\label{item:interpolation} Interpolation of reconstructed output to a common sample rate
%\item\label{item:accumulation} Accumulation of \textsc{snr} from each time slice
%\end{enumerate}
