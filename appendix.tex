\section{Filter bank for generating mock Advanced {\sc ligo} strain data}
\label{appendix:mock-data}

The filter bank described below reproduces the ``zero detuning, high power'' Advanced \textsc{ligo} noise model of  \cite{Shoemaker:2009p9770} very faithfully.  Since it is composed of a small number of third order or lower linear filters, a digital implementation of it can produce mock data in realtime with negligibly few floating point operations.

First, generate 5 independent streams of white Gaussian noise, $x_1, \dots, x_5$, sampled at 16384 Hz.  Next, the apply the (\textsc{f}/\textsc{i})\textsc{ir} filters described in equation~(\ref{eq:iirbank}) to generate $y_1, \dots, y_5$ from $x_1, \dots, x_5$ respectively.  Finally, sum and scale all of the $y_1, \dots, y_5$ together to obtain the final output $y$.

The power spectrum of $y$ is the sum of squares of the magnitudes of the transfer functions of all of the filters.  The output of the filter bank is compared with the noise model in Figure~\ref{fig:mock-psd} below.

The mock Advanced \textsc{ligo} noise generator is implemented by the GStreamer element \texttt{lal\_fakeadvligosrc}, which is included with the analysis code.

\begin{eqnarray}
\label{eq:iirbank}
\fl x_i &[n] \sim& \mathcal{N}[0, 1] \quad \forall \, i, n \nonumber\\\noalign{\vskip 2mm}
\fl y_1 &[n] =& \left(4 \times 10^{-28}\right) x_1[n] - y_1[n-1] + 2 \cdot 0.99995 \cos \left(\frac{2\pi \cdot 9.103}{16384}\right) y_1[n-2] - 0.99995^2 y_1[n-3] \nonumber\\\noalign{\vskip 2mm}
\fl y_2 &[n] =& \left(1.1 \times 10^{-23}\right) (x_2[n] - x_2[n-1]) \nonumber\\\noalign{\vskip 2mm}
\fl y_3 &[n] =& \left(10^{-27}\right) x_3[n] - y_3[n-1] + 2 \cdot 0.999 y_3[n-2] - 0.999^2 y_3[n-3] \nonumber\\\noalign{\vskip 2mm}
\fl y_4 &[n] =& \left(4 \times 10^{-26}\right) x_4[n] - y_4[n-1] + 2 \cdot 0.87 \cos \left(\frac{2\pi \cdot 50}{16384}\right) y_4[n-2] - 0.87 ^ 2 y_4[n-3] \nonumber\\\noalign{\vskip 2mm}
\fl y_5 &[n] =& \left(6.5 \times 10^{-24}\right) x_5[n] - y_5[n-1] - 2 \cdot 0.45 y_5[n-2] - 0.45 ^ 2 y_5[n-3] \nonumber\\\noalign{\vskip 2mm}
\fl \; y &[n] =& \frac{3\sqrt{16384}}{4} \left(y_1[n] + y_2[n] + y_3[n] + y_4[n] + y_5[n]\right)
\end{eqnarray}

\begin{figure}[h!]
\begin{center}
\includegraphics[scale=0.4]{mock_psd.pdf}
\caption{Power spectrum of 100 s of output from mock data filter bank compared with the ``zero detuning, high power'' Advanced \textsc{ligo} noise model.}
\label{fig:mock-psd}
\end{center}
\end{figure}

Note that the \textsc{cpu} overhead of this procedure will be entirely dominated by drawing the pseudorandom numbers $x_1, \dots, x_5$.


\section{Floating point operation counts}

Each addition and each multiplication is counted as a single floating point operation.   We are not assuming that a multiply-accumulate is available as a single operation.

\begin{table}[htdp]
\caption{Number of floating point operations per sample (multiplications and divisions) required for a selection of signal processing operations used in \textsc{lloid}.}
\begin{center}
\setlength{\extrarowheight}{6pt}
\begin{tabular}{l c}
\hline
Process & ops/sample \\
\hline\hline
\textsc{fir} matched filter, M templates of length $n$ & $2 M n$ \\\hline
\textsc{fft} matched filter, M templates of length $n$, blocks of length $D$ & $\frac{4 (M + 1) \lg D + 2 M}{1 - n/D}$ \\\hline
$n$ tap \textsc{fir} resampling filter, sample rates $f_1 < f_2$ & $2 M n f_1 / f_2$ \\\hline
multiply $M \times L$ real matrix by $L\times1$ real vector & $2 M L$ \\\hline
\end{tabular}
\end{center}
\label{table:flops}
\end{table}%


The filter bank can be implemented using finite impulse response (\textsc{fir}) filters, which are just sliding window dot products.  If there are $M$ templates of length $n$, and the data stream contains $N$ samples, then applying the filter bank requires $2 M N n$ operations.

More commonly, the matched filters are implemented using the \textsc{fft} convolution.  This entails applying \textsc{fft}s to blocks of $D$ samples, with $2 n \leq D$, each block overlapping the previous one by $n$ samples.  There are $N/(D-n)$ such blocks.  Modern implementations of the Cooley-Tukey \textsc{fft}, such as the ubiquitous \texttt{fftw}, require about $4 N \lg N$ operations to evaluate a \textsc{dft} of size $N$~\cite{Johnson:2007p9654}.  \editorial{This is more commonly known as ``overlap-save''.  We should find someone else's operation count and cite it.}  A $D$ sample cross-correlation consists of a forward \textsc{fft}, an $D$ sample dot product, and an inverse \textsc{fft}, totaling $8 D \lg N + 2 D$ operations per block.  Per sample, this is $(8 \lg D + 2) / (1 - n/D)$ operations. \editorial{Drew: Why don't we change this to an overlap of $m$ samples so we can see what happens as we increase the overlap to reduce latency.}

The \textsc{fir} filter implementation has the advantage that it has no intrinsic latency, whereas the \textsc{fft} convolution has at least the latency of the \textsc{fft} block size $D \geq 2 n$.  \editorial{Drew: Should the latency be D-n?} For example, for a $1.4 - 1.4 \, M_\odot$ template with duration $\sim 1 \, \mathrm{ks}$, the \textsc{fft} convolution has a latency $\geq 2 \, \mathrm{ks}$.  However, the \textsc{fir} filter implementation has the disadvantage of much greater overhead per sample than the \textsc{fft} convolution.  For a $1\,\mathrm{ks}$ template sampled at $4096\,\mathrm{Hz}$, the \textsc{fir} implementation requires about about $n / 8 \lg 2 n = 2.2 \times 10^4$ times more operations per sample than the \textsc{fft} implementation.



\begin{comment}
% Let's make glitch rejection in LLOID a separate paper.

\section{better noise model}

The assumption that the interferometer noise is well-modeled by a multivariate normal distribution is convenient, but false.  The presence of `glitches' in the interferometer, where the noise statistics change dramatically, is well documented.  Current methods, including ours in the form proposed in the paper, are easily fooled by these bursts of excess power, simply because the analyses assume that the only way that extra power can be introduced to the interferometer is by a gravitational wave.  The gravitational wave hypothesis $H_\mathrm{signal}$ will do a very poor job of explaining temporally coincident incoherent bursts of noise power in the interferometer, but the noise hypothesis $H_\mathrm{signal}$ in its simple form does even worse; the gravitational wave explanation is thus preferred.

We can generalize the noise hypothesis to cope with glitches by creating a model for glitches and adding that hypothesis to the set under consideration.  Like gravitational waves, glitches are infrequent, have poorly known waveforms, and poorly known power.  Unlike gravitational waves, they will not be correlated between instruments.

%The Gursel-Tinto method is not robust against interferometer glitches (nor does it claim to be; real interferometer data doesn't follow the normal distribution assumed in the derivation of the method.)  This is a problem in naive attempts to use the Gursel-Tinto algorithm as a search.  Excess energy of any almost any kind will be interpreted as a evidence of a gravitational wave.  An \emph{ad hoc} addition to the method was propsed in \cite{us}.  A better way forward is to use a noise model that more accurately reflects the 'bursty' or 'glitchy' nature of the data, by replacing the normal noise distribution with a long-tailed distribution.  An immediate problem is that the marginalization integral does not in general have a closed form solution for such distributions.  If we model the long-tailed distribution using two normal distributions the marginalization integral remains tractable.

One first attempt at such a hypothesis is to propose that an interferometer is either `quiet' with some probability $p(H_\mathrm{quiet}|H_\mathrm{noise})$ and has a unit normal noise distribution, or is `glitching' with probability $p(H_\mathrm{glitch}|H_\mathrm{noise})$ and has an increased standard deviation $\sigma_g$

\begin{equation}
P(\mathbf{x}|H_\mathrm{noise})
=
\prod_{i=1}^{N}\left[p(H_\mathrm{quiet}|H_\mathrm{noise})
(2\pi)^{-n/2}
\exp(-\frac{1}{2}\sum_{j=1}^n x_{ij}^2)
+p(H_\mathrm{glitch}|H_\mathrm{noise})
(2\pi)^{-n/2}\sigma_g^{-n}
\exp(-\frac{1}{2\sigma_g^2}\sum_{j=1}^n x_{ij}^2)
\right]\label{eq:glitchy}
\end{equation}

If there is excess energy in only one detector, the new noise hypothesis will readily explain it.  If there is excess energy in three detectors, the noise hypothesis must invoke three coincident glitches and is penalized by $p(H_\mathrm{glitch}|H_\mathrm{noise})^3$ reflecting our belief that triple-coincidence glitches are rare, and the prediction that the glitches are incoherent thinly spreads the hypothesis over a higher-dimensional space than that of the signal hypothesis, which is concentrated around $\mathrm{span}\,\mathbf{F}$. These factors make it possible for the gravitational wave hypothesis to be preferred for some data.

\end{comment}

%Instrumental glitches (hereafter, just `glitches') correspond to noise components with a greater variance than the stationary instrumental noise.

%\label{marg} The evidence for model 1 is most easily calculated in
%the original basis, where the detectors are separable.  In this
%model we assume the glitch or noise outputs of the detectors are
%uncorrelated, so that the overall evidence is simply the product of
%the evidences from each:
%
% \begin{align}
% p(d_i|M_1) &= \int p_i(\sns|M_1)p(d_i|\sns,M_1)\,{\rm d}\sns\\
%            &= \frac{1}{(2\pi)^{1/2}}\left[(1-\alpha_i)\exp(-d_i^2/2) + \frac{\alpha_i}{g_i}\exp(-d_i^2/2g^2)
%            \right],
% \end{align}
%so that
% \begin{align}
% p(\vec{d}|M_1) &= \prod_i p(d_i|M_1)\\
%                &= \frac{1}{(2\pi)^{3/2}}\prod_i \left[(1-\alpha_i)\exp(-d_i^2/2) + \frac{\alpha_i}{g_i}\exp(-d_i^2/2g^2)
%                \right].
% \end{align}

%\begin{widetext}

%Similarly the evidence for model 2 comes straight from
%Eqn.~(\ref{lik2}) by setting $\shs$ to $s^2$,  and $\sns$ to unity,
%so that the overall Bayes factor for a signal to be present is
% \be
% B_{21}=\frac{\exp\left\{ - (\vfph.\,\vec{d})^2/[2(1+s^2|\vfp|^2)]
%                          - (\vfch.\,\vec{d})^2/[2(1+s^2|\vfc|^2)]
%                          - (\vkh\,.\,\vec{d})^2/2 \right\}}
%{[(1+s^2|\vfp|^2)(1+s^2|\vfc|^2)]^{1/2} \prod_i
%\left[(1-\alpha_i)\exp(-d_i^2/2) +
%\frac{\alpha_i}{g_i}\exp(-d_i^2/2g^2)\right]}.
% \label{bayes}
% \ee
%Using the orthogonality relation
% \be
% |\vec{d}|^2 = (\vfph.\,\vec{d})^2 + (\vfch.\,\vec{d})^2 +
% (\vkh\,.\,\vec{d})^2,
% \ee
%this same result may be written in terms of power components in the
%$(\fp,\fc)$-plane and in the total power $ |\vec{d}|^2$:
% \be
% B_{21}=\frac{\displaystyle\exp\left\{ \frac{1}{2}\frac{s^2|\vfp|^2}{(1+s^2|\vfp|^2)}(\vfph.\,\vec{d})^2
%                         +\frac{1}{2}\frac{s^2|\vfc|^2}{(1+s^2|\vfc|^2)}(\vfch.\,\vec{d})^2
%                          \right\}}
%{[(1+s^2|\vfp|^2)(1+s^2|\vfc|^2)]^{1/2} \displaystyle\prod_i
%\left\{(1-\alpha_i)\displaystyle\exp\left(-\frac{d_i^2}{2}\right) +
%\displaystyle\frac{\alpha_i}{g_i}\displaystyle\exp\left[\frac{1}{2}\left(1-\frac{1}{g_i^2}\right)d_i^2\right]\right\}}.
% \ee
%
% Consider the simplified scenario in which model 1 assumes all three
%detectors are currently glitching, so that $\alpha=1$, and where the
%characteristic glitch power is the same in each, so that
%$g_i^2=g^2$. The Bayes factor is now comparing the idea that (1) we
%are seeing a triple-coincidence glitch with (2) we are seeing a
%gravitational wave, and Eqn.~(\ref{bayes}) reduces to
% \be
% B_{21}=\frac{g^3\exp\left\{\displaystyle \frac{|\vec{d}|^2}{2g^2} -
% \left[\frac{(\vfph.\,\vec{d})^2}{2(1+s^2|\vfp|^2)}
%                          +
%                          \frac{(\vfch.\,\vec{d})^2}{2(1+s^2|\vfc|^2)}
%                          + \frac{(\vkh\,.\,\vec{d})^2}{2}\right] \right\}}
%{[(1+s^2|\vfp|^2)(1+s^2|\vfc|^2)]^{1/2} }.
% \ee
%The exponent is simply the difference between the chisquared
%statistic for a glitch of mean power $g^2$ and that for a
%gravitational wave signal of mean power $s^2$.  The other terms
%represent an Occam factor, reflecting the difference in the sizes of
%the competing hypothesis spaces.
%
%The same expression can be written as
% \be
% B_{21}=\frac{g^3\exp\left[ %\displaystyle
%              \frac{1}{2}\left(\frac{1}{g^2}-\frac{1}{1+s^2|\vfp|^2}\right)(\vfph.\,\vec{d})^2
%             +\frac{1}{2}\left(\frac{1}{g^2}-\frac{1}{1+s^2|\vfc|^2}\right)(\vfch.\,\vec{d})^2
%             -\frac{1}{2}\left(1-\frac{1}{g^2}\right) (\vkh\,.\,\vec{d})^2 \right]}
%         {[(1+s^2|\vfp|^2)(1+s^2|\vfc|^2)]^{1/2} },
% \ee
%to highlight the fact that power in the null-stream direction $\vkh$
%always reduces $B$.

%\end{widetext}
