\section{Implementation}
\label{sec:implementation}

In this section we describe an implementation of the \lloid\ method described
in section \ref{sec:method} suitable for rapid \GW{}
searches for \CBC{}s.  The \lloid\ method requires several
computations that can be completed before the analysis is underway.  Thus
we divide the procedure into an offline planning stage and an
online, low-latency filtering stage.  The offline stage can be done before the
analysis is started and updated asynchronously, whereas the online stage must
keep up with the detector output and produce search results as rapidly as
possible.  In the next two subsections we describe what these stages entail.

\subsection{Planning stage}

The planning stage begins with choosing templates that cover the space of
source parameters with a hexagonal grid~\citep{PhysRevD.76.102004} in order to
satisfy a minimum match criterion.  This assures a prescribed maximum loss in
\SNR\ for signals whose parameters do not lie on the hexagonal grid.  Next, the
grid is partitioned into groups of neighbors called \emph{sub-banks} that
are appropriately sized so that each sub-bank can be efficiently handled by a
single computer.  The sub-banks are chosen to have comparable chirp mass, which
groups together templates with similar time-frequency evolution.  Dividing the source
parameter space into smaller sub-banks also reduces the offline cost of the
\SVD{} and is the approach considered in \citet{Cannon:2010p10398}.  Next, we choose
time-slice boundaries as in equation~\eqref{eq:time-sliced-templates} such that all
of the templates within a sub-bank are sub-critically sampled at progressively lower
sample rates.  For each time slice, the templates are downsampled to the
appropriate sample rate.  Finally, the \SVD\ is applied to each time slice in
the sub-bank in order to produce a set of orthonormal basis templates and a
reconstruction matrix that maps them back to the original templates as
described in equation~\eqref{eq:svddecomp}.  The downsampled basis templates,
the reconstruction matrix, and the time-slice boundaries are all saved to disk.

\subsection{Filtering stage}

The \lloid\ algorithm is amenable to truly latency free, real-time implementation.
However, such a real-time search pipeline would likely require integration directly into
the data acquisition and storage system of the \LIGO\ observatories.  A slightly more 
modest goal is to leverage existing low-latency, but not real-time, signal processing
software in order to implement the \lloid\ algorithm.

We have implemented a prototype of the low-latency filtering stage using an
open-source signal processing environment called
\gstreamer\footnote{\url{http://gstreamer.net/}}.
\gstreamer\ is a vital component of many Linux systems, providing media
playback, authoring, and streaming on devices from cell phones to desktop
computers to streaming media servers.  Given the similarities of
\GW{} detector data to audio data it is not surprising that
\gstreamer\ is useful for our purpose. \gstreamer\ also provides some useful
stock signal processing elements such as resamplers and filters.  We have
extended the \gstreamer\ framework by developing a library called
\gstlal\footnote{\url{https://www.lsc-group.phys.uwm.edu/daswg/projects/gstlal.html}}
that provides elements for \GW{} data analysis.

\paragraph{Decimation}

The whitened detector data is reduced to successively
lower sample rates by decimation. Decimation involves applying an anti-aliasing
filter to the data, and then down-sampling by deleting samples.  We use a
192-tap \fir\ decimator provided by \gstreamer{}'s {\tt audioresample}
element.  The detector data is provided at every power-of-two sample rate
required by the time slices described in \eqref{eq:time-slices}.  At this point,
the \gstreamer\ pipeline splits into several parallel branches to handle each
time slice.  Next, these decimated data streams are fed into parallel \fir\ filter banks.

\paragraph{Basis filters}

The basis filters are implemented using a \gstlal\ element called {\tt
lal\_firbank}, which provides a single input, multiple output bank of \fir\ filters
from a matrix of filter coefficients.  Several instances of {\tt lal\_firbank}
execute in parallel to handle each of the time slices.  Filter coefficients are taken
from the nonzero samples of the time slices in equation~\eqref{eq:time-sliced-templates},
with the zero-padding effectively accomplished by appropriate delays.

\paragraph{Reconstruction}

From the outputs of the \SVD\ basis filters, we form the partial \SNR\ streams
for each time  slice by multiplying by the reconstruction matrices.  This is
accomplished with the \texttt{gstlal} element \texttt{lal\_matrixmixer}.

\paragraph{Interpolation}

In order to form the early-warning output from each time slice, we have to add
the partial \SNR\ to the early-warning output from the subsequent time slices.
If the next time slice does not have the same sample rate, its output must
first be interpolated.  The \gstreamer\ element {\tt audioresample} is used here.  

\paragraph{\SNR\ accumulation}

The early-warning output for each time slice is formed by accumulating
interpolated early-warning output from the subsequent time slice.  This process
continues until we have worked our way to the \SNR\ of the original templates
at the full sample rate $f^0$.  In this way, the \lloid\ algorithm and this
implementation naturally leads to a simple early-warning pipeline.
